{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2rNJKxq1fTI",
    "outputId": "fe75e172-492a-42d0-d306-7babe59dd743",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# This is for installing model trees, that will be used at the end\n",
    "!pip install --upgrade linear-tree\n",
    "\n",
    "# More info about this implementation of model trees\n",
    "# https://towardsdatascience.com/linear-tree-the-perfect-mix-of-linear-model-and-decision-tree-2eaed21936b7\n",
    "# https://pypi.org/project/linear-tree/\n",
    "\n",
    "# Install statsmodels for confidence intervals\n",
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWAOeLZ94XOz"
   },
   "source": [
    "# Using Python:\n",
    "- Base Python (python without extra libraries): lists, dictionaries, sets, ...\n",
    "- numpy: vectors and matrices with numbers\n",
    "- pandas: data.frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MS7sU2en7dVC"
   },
   "source": [
    "This is a list (base Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FfuwVwX65nqi",
    "outputId": "024bfb22-e237-4f77-da13-5c41b2bbd70b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAEx9NdA7jby"
   },
   "source": [
    "This is a numpy vector and a numpy matrix. They can only contain numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9kybjyy77jra",
    "outputId": "6a5460b5-74fe-42a3-a70e-7abc412a054e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a vector:\n",
      "[1 2 3]\n",
      "\n",
      "Ths is a matrix:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('This is a vector:')\n",
    "\n",
    "a = np.array([1, 2, 3])\n",
    "print(a)\n",
    "\n",
    "print()\n",
    "\n",
    "print('Ths is a matrix:')\n",
    "b = np.array([[1,2,3], \n",
    "              [4,5,6]])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1NceMWE8FDD"
   },
   "source": [
    "This is a pandas dataframe. It can contain different columns, some of them with numbers, some of them with categorical values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "mt5NzVA18FM6",
    "outputId": "df66e526-e99e-4ee0-c0ff-ad9fc70e34c0"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 45] Operation not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:982\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:925\u001b[0m, in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1414\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1383\u001b[0m, in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1347\u001b[0m, in \u001b[0;36m_path_importer_cache\u001b[0;34m(cls, path)\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 45] Operation not supported"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame({'a':[1,2,3], 'b':['a', 'b', 'c']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2iDVRYc9fFi"
   },
   "source": [
    "It looks that pandas dataframes are the appropriate data structure for representing data. However, scikit-learn can only use numpy matrices. Therefore, categorical values must be encoded as numbers. The typical workflow when working with scikit-learn is:\n",
    "1. Load data as a Pandas dataframe\n",
    "2. Do EDA (Exploratory Data Analysis) to understand your data\n",
    "3. Encode the Pandas dataframe as a numpy matrix (get rid of categorical values and missing values)\n",
    "4. Do machine learning with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9dwWGrb4QXi"
   },
   "source": [
    "# Scikit-learn (sklearn): \n",
    "- Collection of machine learning algorithms and tools in Python.\n",
    "- [http://scikit-learn.org/stable/](SCIKIT-LEARN)\n",
    "\n",
    "** Other packages for Machine Learning in Python: **\n",
    "- Pylearn2\n",
    "- PyBrain\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DL5_Er0v4QXl"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Input data for sklearn (numeric matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-3u_OGV4QXm"
   },
   "source": [
    "- Datasets for sklearn are numpy **numeric** matrices:\n",
    "- This implies that categorical attributes/features must be represented as:\t\n",
    "    - Integers\n",
    "    - One-hot-encoding / dummy variables\n",
    "\n",
    "- However, there is a trend for integrating Pandas dataframes with scikit learn\n",
    "- Missing values are represented as np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMtbmEyl4QXm"
   },
   "source": [
    "- A simple example of dataset is the iris dataset, which is included within sklearn itself.\n",
    "- Otherwise, we would have to load it from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SwhF9rEr4QXm"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 45] Operation not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_iris\n\u001b[1;32m      3\u001b[0m iris_meta \u001b[38;5;241m=\u001b[39m load_iris()\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:982\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:925\u001b[0m, in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1414\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1383\u001b[0m, in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1347\u001b[0m, in \u001b[0;36m_path_importer_cache\u001b[0;34m(cls, path)\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 45] Operation not supported"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "iris_meta = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4XLUUY-4QXn",
    "outputId": "a64bafc1-8f37-49b9-f019-64839c38b919",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(iris_meta.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BraxjcIT4QXo",
    "outputId": "a159d5bb-7a56-45c8-f50f-770e8d1b8dea"
   },
   "outputs": [],
   "source": [
    "print(iris_meta.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUWlrFzX4QXp"
   },
   "source": [
    "This is the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wETZD6q64QXp"
   },
   "outputs": [],
   "source": [
    "X = iris_meta.data\n",
    "y = iris_meta.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTfFws3S4QXq"
   },
   "source": [
    "- We can see that X (the input features) is a 2-dimensional numpy array\n",
    "- and y (the response variable) is a numpy vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tTf1ylam4QXq",
    "outputId": "978cbd69-0d1c-4a56-85af-9cb820fd1a6d"
   },
   "outputs": [],
   "source": [
    "print(type(X))\n",
    "print(X.shape) # 150 instances and 4 input features\n",
    "print(X.dtype) # Values are real numbers (float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQb5GqPa4QXq",
    "outputId": "b28a1b6b-d47e-456c-c046-b546f4886c25"
   },
   "outputs": [],
   "source": [
    "print(type(y))\n",
    "print(y.shape) # 150 values of the response variable\n",
    "print(y.dtype) # Values are integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1MSNYt04QXr"
   },
   "source": [
    "Let's visualize the first 10 instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-UOb_pJx4QXr",
    "outputId": "e0e1bc7a-707a-4151-8581-8b658c3060df"
   },
   "outputs": [],
   "source": [
    "print(X[0:10,0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oa8xhgG34QXr",
    "outputId": "042991e6-5b6f-47bc-db27-913cbe90a74e"
   },
   "outputs": [],
   "source": [
    "print(y[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GL8zQzuh4QXr"
   },
   "source": [
    "Below, we visualize the whole table, with the response variable being the last column.\n",
    "It is not necessary to do this when working with sklearn, it is just for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LASHXWc74QXs",
    "outputId": "2bf91464-6f2a-43b1-fa07-9e7c8d329fd2"
   },
   "outputs": [],
   "source": [
    "np.concatenate((X,y[:,np.newaxis]), axis=1)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rke_0WUy4QXs"
   },
   "source": [
    "We can plot the iris dataset to see how it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "SUtaFKIH4QXs",
    "outputId": "be88f514-9450-4d5b-d853-030fb3f7661f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1HKbQlo4QXs"
   },
   "source": [
    "# Training a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9zidraxu4QXt",
    "outputId": "9f29054b-0de9-4d5c-8feb-fd7efbe859cf"
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "# Here, we define the type of training method (nothing happens yet)\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "# Now, we train (fit) the method on the (X,y) dataset\n",
    "clf.fit(X, y)\n",
    "# clf **has been changed** and now contains the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgtYgDGH4QXt"
   },
   "source": [
    "We can visualize the tree as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HXdfMAUC4QXt",
    "outputId": "81c6465c-b0c6-4d26-e118-fe258c23b549"
   },
   "outputs": [],
   "source": [
    "text_representation = tree.export_text(clf, feature_names=iris_meta.feature_names)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvjUKYTd4QXt"
   },
   "source": [
    "We can also visualize the tree graphically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "id": "LPEoeoGc4QXu",
    "outputId": "fcd77528-65cf-40e0-fc37-b27c577085e1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(clf,\n",
    "                   feature_names = iris_meta.feature_names,\n",
    "                   class_names=iris_meta.target_names,\n",
    "                   filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDexRXHP4QXu"
   },
   "source": [
    "# Training and evaluating a decision tree with a test set (holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7uNOyNv4QXu"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-4APKeP4QXu"
   },
   "source": [
    "- Now we create the training (X_train, y_train) and testing (X_test, y_test) partitions: 2/3 for training, 1/3 for testing\n",
    "- Notice the **random_state=42** for reproducibility (important!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSfsVFxH4QXu"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OQ_uQ0CelIl",
    "outputId": "798e9abd-e2b7-48f8-b26e-239f40477125"
   },
   "outputs": [],
   "source": [
    "X_train[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1OxaH3-4QXv"
   },
   "source": [
    "Shape of the training and testing partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sLayO_Ir4QXv",
    "outputId": "7518d699-0b4b-46f0-dda9-140783f2b63b"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape) # 100 instances for training\n",
    "print(X_test.shape, y_test.shape)   # 50 instances for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fxjyn5es4QXv"
   },
   "source": [
    "Let's print the five first training instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jS3dEvOK4QXv",
    "outputId": "4326689d-b25c-4ae1-d0e1-958ec001156a"
   },
   "outputs": [],
   "source": [
    "print(\"INPUT FEATURES:\")\n",
    "print(X_train[:5,:])\n",
    "print(\"RESPONSE:\")\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-hCi0G-4QXv"
   },
   "source": [
    "If we create the partition again, it will be the same as before if we use the same random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EMUbPInn4QXv",
    "outputId": "5998aef7-a03a-44f7-f94f-f2cbe469b0be"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print(\"INPUT FEATURES:\")\n",
    "print(X_train[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJwTUDiv4QXv"
   },
   "source": [
    "But it will be different if we change the random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C9iUH1c14QXw",
    "outputId": "026d29c4-d3cf-42a0-b24b-f0a051073b02"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=24)\n",
    "print(\"INPUT FEATURES:\")\n",
    "print(X_train[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwiXO5WR4QXw"
   },
   "outputs": [],
   "source": [
    "# Let's keep the original partition (with random state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2W36mNPh4QXw"
   },
   "source": [
    "- Now, we train the tree with .fit\n",
    "- Notice that we use np.random.seed(42) so that the training of the tree is also reproducible (in case that tree training is not deterministic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pGUABN5a4QXw",
    "outputId": "4c2966b6-1d80-4789-e552-5ddedc3eb043"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "\n",
    "# Here, we set our model to classification tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "# Making results reproducible, in case training a tree contains random decisions\n",
    "np.random.seed(42)\n",
    "# Now, we train it\n",
    "clf.fit(X_train, y_train)\n",
    "# We can see that the tree is inside\n",
    "print(tree.export_text(clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsF1kKuQ4QXw"
   },
   "source": [
    "By the way, we can get help of any function (like .fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "my616HwN4QXw"
   },
   "outputs": [],
   "source": [
    "?clf.fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jqPY0dT4QXw"
   },
   "source": [
    "Now, we evaluate the tree, by computing predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCGTo5oO4QXx"
   },
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfu7AeHg4QXx"
   },
   "source": [
    "We can check the predictions for the testing instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VEzdzi7_4QXx",
    "outputId": "a679b6c0-c1db-4d41-a5c6-7d4e03cdec37"
   },
   "outputs": [],
   "source": [
    "print(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qgkCQxm4QXx"
   },
   "source": [
    "For the sake of visualization, we can compare predictions and actual values (ground truth of the response variable). We can see that for the first 5 instances, it is always correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-K2BLDm24QXx",
    "outputId": "f537d746-8243-44cd-dd2e-68b4dc5558e4"
   },
   "outputs": [],
   "source": [
    "print(np.hstack((y_test_pred[:5,np.newaxis], y_test[:5,np.newaxis])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCpZW27s4QXx"
   },
   "source": [
    "- But, in order to evaluate the model on the test partition, we can compute a metric (classification accuracy in this case)\n",
    "- It is very high (98%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uspUaRJe4QXx",
    "outputId": "bb0892eb-785d-4d4d-977e-e62471e77861"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "accuracy_tree = metrics.accuracy_score(y_test, y_test_pred)\n",
    "print(accuracy_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CjgSbJvq4QXx"
   },
   "source": [
    "However, the 0.98 accuracy is the model evaluation (estimation of performance). We still need to compute the final model (the one that will be sent and used by the company) **using all available data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VN0n0ZU94QXy",
    "outputId": "94ec2925-86c9-4f74-cee3-2efcadf5372b"
   },
   "outputs": [],
   "source": [
    "final_clf = tree.DecisionTreeClassifier()\n",
    "# Making results reproducible, in case training a tree contains random decisions\n",
    "np.random.seed(42)\n",
    "# Now, we train it\n",
    "final_clf.fit(X, y)\n",
    "# final_clf contains the model that would be used by the company\n",
    "# Its estimated accuracy is what we computed before (95%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Bzm7znT4QXy"
   },
   "source": [
    "By the way, we can store (and load) this model on a file. This is called \"model persistence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_ukcKMF4QXy"
   },
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "# Save the final model to a file\n",
    "dump(final_clf, 'final_tree.joblib') \n",
    "# Load the tree from the file\n",
    "final_clf_reloaded = load('final_tree.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObJu3av94QXy"
   },
   "source": [
    "Below, you have the complete code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fv2Zgzb94QXy",
    "outputId": "48de4500-3cb6-4182-97f9-5d8f61b943a6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Here, we set our model to classification tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "np.random.seed(42) # reproducibility\n",
    "# We train it\n",
    "clf.fit(X_train, y_train)\n",
    "# We obtain predictions on the test set\n",
    "y_test_pred = clf.predict(X_test)\n",
    "# We compute accuracy\n",
    "accuracy_tree = metrics.accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Accuracy of the tree: {accuracy_tree} \")\n",
    "\n",
    "# We finally compute the final model with all available data\n",
    "\n",
    "final_clf = tree.DecisionTreeClassifier()\n",
    "np.random.seed(42)  # reproducibility\n",
    "final_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7lsOqmTBnzt"
   },
   "source": [
    "# Exercise: do the fit, predict, model evaluation, and final_model construction  with KNN.\n",
    "\n",
    "- This one can be used for classification:\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "- This one can be used for regression:\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VSb9cSjfNafr",
    "outputId": "04da8f54-bc77-429c-dc95-9b821d012dfd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Here, we set our model to classification tree\n",
    "clf = KNeighborsClassifier()\n",
    "np.random.seed(42) # reproducibility\n",
    "# We train it\n",
    "clf.fit(X_train, y_train)\n",
    "# We obtain predictions on the test set\n",
    "y_test_pred = clf.predict(X_test)\n",
    "# We compute accuracy\n",
    "accuracy_knn = metrics.accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Accuracy of KNN: {accuracy_knn} \")\n",
    "\n",
    "# We finally compute the final model with all available data\n",
    "\n",
    "final_clf = KNeighborsClassifier()\n",
    "np.random.seed(42)  # reproducibility\n",
    "final_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hX9_a4E94QXy"
   },
   "source": [
    "# Training and evaluating a decision tree with crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiMzev7a4QX0"
   },
   "source": [
    "- First, we are going to do crossvalidation with a loop, so that we understand the process better\n",
    "- However (!!), it is better to do crossvalidation with the cross_val_score function, as we will do later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r121gQdC4QX0"
   },
   "source": [
    "- KFold creates the training/test crossvalidation folds.\n",
    "    - shuffle randomly shuffles the data before splitting the folds. We should always do this, unless we have good reasons otherwise\n",
    "    - random_state makes the shuffling reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECsSw2by4QX0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bOHa6wQ4QX0"
   },
   "source": [
    "- Now, we carry out crossvalidation by going through all 5 folds.\n",
    "- In every iteration:\n",
    "    - We train a model on the training folds\n",
    "    - We compute predictions on the testing folds\n",
    "    - We compute the metric (accuracy) and store it\n",
    "- When the crossvalidation loop ends, we compute the average (and std)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wI_3sDaF4QX0",
    "outputId": "1fcc92b7-9db0-411c-94b8-de6b06a1ac6f"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42) # reproducibility\n",
    "\n",
    "# This variable will contain the 5 crossvalidation accuracies, one per iteration\n",
    "scores = []\n",
    "\n",
    "for train_index, test_index in cv.split(X):\n",
    "    print(f\"TRAIN: {train_index[:5]} ...\", f\"TEST: {test_index[:5]} ...\")\n",
    "    # Getting the actual training and testing partitions out of the indices\n",
    "    X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "  \n",
    "    # Training the model for this particular crossvalidation iteration\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    accuracy_tree = metrics.accuracy_score(y_test, y_test_pred)  \n",
    "    \n",
    "    print(f\"The accuracy for this crossval iteration is: {accuracy_tree}\")\n",
    "    print()\n",
    "    # We add this accuracy to the list\n",
    "    scores.append(accuracy_tree)\n",
    "    \n",
    "# Transforming scores from list to numpy array (this is just a technicallity)    \n",
    "scores = np.array(scores)  \n",
    "print(f\"All the accuracies are: {scores}\")\n",
    "print(f\"And the average crossvalidation accuracy is: {scores.mean():.2f} +- {scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7dfsh8t4QX0"
   },
   "source": [
    "- However, before we programmed the loop explicitely, in order to understand what crossvalidation does.\n",
    "- But crossvalidation is typically done by means of the cross_val_score function, as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejuZVow54QX1",
    "outputId": "744cc773-4352-482a-aab8-3ad9e6ea2ad3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# create a k-fold crossvalidation iterator of k=5 folds\n",
    "# shuffle = True randomly rearranges the dataframe\n",
    "# random_state = 42 is for making the folds reproducible\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Making model training reproducible\n",
    "np.random.seed(42)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, scoring='accuracy', cv = cv) \n",
    "\n",
    "print(f\"All the accuracies are: {scores}\")\n",
    "print(f\"And the average crossvalidation accuracy is: {scores.mean():.2f} +- {scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INNQMn8n4QX1"
   },
   "source": [
    "- 0.95 is the model evaluation (estimation of performance).\n",
    "- But the final model has to be trained with all available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yNXty5034QX1",
    "outputId": "4abe0e39-6c06-426a-f22d-f99d980e1752"
   },
   "outputs": [],
   "source": [
    "final_clf = tree.DecisionTreeClassifier()\n",
    "# Making results reproducible, in case training a tree contains random decisions\n",
    "np.random.seed(42)\n",
    "# Now, we train it\n",
    "final_clf.fit(X, y)\n",
    "# final_clf contains the model that would be used by the company\n",
    "# Its estimated accuracy is what we computed before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prQCnIMt4QX1"
   },
   "source": [
    "Below, you have the complete code for crossvalidation evaluation (and also obtaining the final model at the end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZT8P6pJz4QX1",
    "outputId": "b9e780a5-b8db-45ce-9e8b-ee699cb3eb1e"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# create a k-fold crossvalidation iterator of k=5 folds\n",
    "# shuffle = True randomly rearranges the dataframe\n",
    "# random_state = 42 is for making the folds reproducible\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Making model training reproducible\n",
    "np.random.seed(42)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, scoring='accuracy', cv = cv) \n",
    "\n",
    "# print(f\"All the accuracies are: {scores}\")\n",
    "print(f\"The average crossvalidation accuracy is: {scores.mean():.2f} +- {scores.std():.2f}\")\n",
    "\n",
    "final_clf = tree.DecisionTreeClassifier()\n",
    "# Making results reproducible, in case training a tree contains random decisions\n",
    "np.random.seed(42)\n",
    "# Now, we train it\n",
    "final_clf.fit(X, y)\n",
    "# final_clf contains the model that would be used by the company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7FP2q4V4QX1"
   },
   "source": [
    "# Changing hyperparameters of a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewZT0QkW4QX1"
   },
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Q_jHJgb4QX1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0eoV0e54QX2"
   },
   "source": [
    "Let's see the effect of changing from gini to entropy. We use holdout here. It seems that results are exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eN-4gAJg4QX2",
    "outputId": "ba897cbc-29b2-4088-e9e4-859b31e5ef84"
   },
   "outputs": [],
   "source": [
    "# This loop checks what happens with the two criterions\n",
    "for criterion in [\"gini\", \"entropy\"]:\n",
    "    clf = tree.DecisionTreeClassifier(criterion=criterion)\n",
    "    np.random.seed(42)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    accuracy_tree = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"With {criterion}: {accuracy_tree:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgKDmuV84QX2"
   },
   "source": [
    "Let's see the effects of maximum_depth. \"None\" represents the maximum possible depth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHjavMZk4QX2",
    "outputId": "9231ca9d-4e0e-4457-fa46-28ba7c49919a"
   },
   "outputs": [],
   "source": [
    "for max_depth in [1,2,3,None]:\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=max_depth)\n",
    "    np.random.seed(42)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    accuracy_tree = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"With max_depth {max_depth}: {accuracy_tree:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZ1FfR1l4QX2"
   },
   "source": [
    "It seems that max_depth=2 is enough. Let's visualize a tree with max depth = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "2ipRiYjF4QX2",
    "outputId": "ec449e39-216d-4726-95fc-708351da964b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=2)\n",
    "np.random.seed(42)\n",
    "clf.fit(X_train,y_train)\n",
    "    \n",
    "_ = tree.plot_tree(clf,\n",
    "                   feature_names = iris_meta.feature_names,\n",
    "                   class_names=iris_meta.target_names,\n",
    "                   filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-Vh6got4QX2"
   },
   "source": [
    "Let's see the effects of min_samples_split. 2 is the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1BeviS94QX2",
    "outputId": "d0e54102-12de-4226-8041-aac2e75bb7fd"
   },
   "outputs": [],
   "source": [
    "for min_samples in [2,10,20,30,100]:\n",
    "    clf = tree.DecisionTreeClassifier(min_samples_split=min_samples)\n",
    "    np.random.seed(42)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    accuracy_tree = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"With min_samples_split {min_samples}: {accuracy_tree:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZkXAUuStFKid"
   },
   "source": [
    "Finally, let's check another hyper-parameter called min_impurity_decrease: this means that a new level of the tree is created only if the information gain (that is, the decrease in entropy or gini) is larger than min_impurity_decrease. It is yet another way of controlling tree depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Su3NPiA94QX3",
    "outputId": "58435880-4240-4af7-a320-630c80c218d3"
   },
   "outputs": [],
   "source": [
    "for min_impurity_decrease in np.linspace(0,2,num=10):\n",
    "    clf = tree.DecisionTreeClassifier(min_impurity_decrease=min_impurity_decrease)\n",
    "    np.random.seed(42)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    accuracy_tree = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"With min_impurity_decrease {min_impurity_decrease}: {accuracy_tree:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAJYiJr1OYmz"
   },
   "source": [
    "# Exercise: check the effect of changing hyper-parameter number of neighbors of KNN.\n",
    "\n",
    "Help about KNN in sklearn:\n",
    "\n",
    "KNN for classification is:\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "It can be defined with:\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "(and then trained with .fit).\n",
    "\n",
    "Help for KNN for classification here:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "You can also check what happens when you change hyper-parameter weights, that can have three different values:\n",
    "\n",
    "- ‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.\n",
    "\n",
    "- ‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BnCg6h_MCPM4",
    "outputId": "2d6f9ff8-38d3-411c-fd5c-f9e36d3f0752"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "for k in range(1,100,5):\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    np.random.seed(42)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    accuracy_knn = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"With k neighbors {k}: {accuracy_knn:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFONncXU4QX3"
   },
   "source": [
    "# Dealing with categorical variables in DecisionTreeClassifier\n",
    "\n",
    "- Sklearn implementation of trees CANNOT deal with categorical variables (in most cases).\n",
    "- They must be converted to dummy variables (one-hot-encoding)\n",
    "- Sklearn trees cannot deal with missing values either\n",
    "\n",
    "The typical workflow when working with scikit-learn is:\n",
    "\n",
    "1. Load data as a Pandas dataframe\n",
    "\n",
    "2. Do EDA (Exploratory Data Analysis) to understand your data. And this means:\n",
    "  - How many instances and attributes there are\n",
    "  - What type of attributes there are (numerical or categorical). This is done to check whether there are categorical features that should be encoded (as dummies / one-hot-encoding)\n",
    "  - What attributes have missing values, and how many\n",
    "  - Whether it is a classification or a regression problem (response variable), and in case of classification, whether the class is imbalanced.\n",
    "\n",
    "3. Encode the Pandas dataframe as a numpy matrix (get rid of categorical values and missing values)\n",
    "\n",
    "4. Do machine learning with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "y5_UHlRVJqtw",
    "outputId": "be4f112a-81eb-4614-aa84-579b0ab539e7"
   },
   "outputs": [],
   "source": [
    "# This is for uploading tennis.txt from your hard drive into Colab\n",
    "\n",
    "from google.colab import files\n",
    "import io\n",
    "uploaded = files.upload()\n",
    "tennis_tmp = io.BytesIO(uploaded['tennis.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueoMs8uHk2vw"
   },
   "outputs": [],
   "source": [
    "# There are other ways of accessing files from google colab \n",
    "# https://neptune.ai/blog/google-colab-dealing-with-files\n",
    "# Code below allows to mount your google drive and load data directly from GD\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGwW0YWM4QX3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tennis_df = pd.read_csv(\"tennis.txt\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-jAr-k5KQfe"
   },
   "source": [
    "We can check the first instances of sky with head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "C6fyz7ae4QX3",
    "outputId": "6b1520eb-6b6b-446a-a7e7-db8d50e39496"
   },
   "outputs": [],
   "source": [
    "tennis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mdqmMcdKYcl"
   },
   "source": [
    "With this dataset is very small, so we can visualize it whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "pGckFPDlKdc2",
    "outputId": "f2feeff2-ed60-47b3-be5b-04ee4da8652e"
   },
   "outputs": [],
   "source": [
    "tennis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vw_EJnkwLD9d",
    "outputId": "16b0a859-c5f8-48c4-e00d-c04151686caf"
   },
   "outputs": [],
   "source": [
    "print('The shape of the data table is:')\n",
    "print('===============================')\n",
    "print(tennis_df.shape)\n",
    "print()\n",
    "\n",
    "print('The types of the attributes are:')\n",
    "print('================================')\n",
    "tennis_df.info()\n",
    "\n",
    "print()\n",
    "\n",
    "print('How many missing values per attribute:')\n",
    "print('======================================')\n",
    "print(tennis_df.isnull().sum())\n",
    "\n",
    "print()\n",
    "\n",
    "print('Fraction of missing values per attribute:')\n",
    "print('======================================')\n",
    "print(tennis_df.isnull().mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WpY6Yu8PPFm"
   },
   "source": [
    "Finally, we check whether the response variable is imbalanced. We can see it is not too imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rG4XjXvQPJ61",
    "outputId": "b4b033f3-5cb3-4ac1-c303-dbaaba114ab6"
   },
   "outputs": [],
   "source": [
    "print(tennis_df.Play.value_counts())\n",
    "\n",
    "print()\n",
    "\n",
    "print(tennis_df['Play'].value_counts())\n",
    "\n",
    "print()\n",
    "\n",
    "print(tennis_df['Play'].value_counts()/tennis_df['Play'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6T8D5USxa34S"
   },
   "source": [
    "Now, we are going to encode:\n",
    "- Our categorical features (Sky and Windy)\n",
    "- The response variable (the class: Play)\n",
    "\n",
    "But first, we will separate the data table into inputs (X) and output (y)\n",
    "\n",
    "We will use a ColumnTransformer, that allows to process only some particular columns, and leaves the others untouched (passthrough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XLHZORsa0yz",
    "outputId": "ddbb0276-70de-48ae-8c37-63ccc8de0383"
   },
   "outputs": [],
   "source": [
    "y_df = tennis_df['Play']\n",
    "print(y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6SKomsD9bgQU",
    "outputId": "9f9654d7-f0d8-4ff1-cd0d-5cf77a90fe0e"
   },
   "outputs": [],
   "source": [
    "X_df = tennis_df.drop('Play', axis=1)\n",
    "print(X_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzuEqVg3a1ea"
   },
   "source": [
    "We will use now a ColumnTransformer, that allows to process only some particular columns, and leaves the others untouched (passthrough). In this case, we will process only the categorical ones. \n",
    "The output of this transformation is a numpy matrix (!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwdnSKoRA9CO",
    "outputId": "7e6672c4-1cfb-4e89-b677-16e2b17b243c"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# numeric_features = ['Temperature', 'Humidity']\n",
    "categorical_features = ['Sky', 'Windy']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [ \n",
    "                    ('categorical', OneHotEncoder(handle_unknown='ignore'), \n",
    "                                    categorical_features)\n",
    "                    ],\n",
    "                    remainder='passthrough' \n",
    ")\n",
    "\n",
    "preprocessor.fit(X_df)\n",
    "X = preprocessor.transform(X_df)\n",
    "\n",
    "# Notice that now we have 7 columnos\n",
    "print(X.shape)\n",
    "print()\n",
    "\n",
    "# Notice that now the type of the data matrix is numpy, which can already be used by sklearn\n",
    "print(type(X))\n",
    "print()\n",
    "\n",
    "# The first three columns are the dummies for Sky, the second two columns are the dummies for Windy\n",
    "# The last two columns are Temperature and Humidity, untouched\n",
    "# Please, notice that the order of columns has changed (not important, in principle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2WGtsLHX4QX4",
    "outputId": "20368656-cb14-4f61-c4ef-01419c763d2d"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# numeric_features = ['Temperature', 'Humidity']\n",
    "categorical_features = ['Sky', 'Windy']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [ \n",
    "                    ('categorical', OneHotEncoder(drop='if_binary', \n",
    "                                                  handle_unknown='ignore'), \n",
    "                                    categorical_features)\n",
    "                    ],\n",
    "                    remainder='passthrough' \n",
    ")\n",
    "\n",
    "preprocessor.fit(X_df)\n",
    "X = preprocessor.transform(X_df)\n",
    "\n",
    "# Notice that now we have 6 columnos\n",
    "print(X.shape)\n",
    "print()\n",
    "\n",
    "# Notice that now the type of the data matrix is numpy, which can already be used by sklearn\n",
    "print(type(X))\n",
    "print()\n",
    "\n",
    "# The first three columns are the dummies for Sky, the second column is the dummy for Windy\n",
    "# The last two columns are Temperature and Humidity, untouched\n",
    "# Please, notice that the order of columns has changed, but the last versions of sklearn\n",
    "# return the names of variables, which is useful to understand where the variables come from\n",
    "\n",
    "print(X)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(list(preprocessor.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQ7O7ElKoyDp"
   },
   "source": [
    "Sometimes it is time consuming to enumerate all categorical columns. We can use make_column_selector / selector in order to select the types we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4ATnGozohJZ",
    "outputId": "fcc22251-c09d-4b24-c72d-1f647183196b"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "# numeric_features = ['Temperature', 'Humidity']\n",
    "categorical_features = ['Sky', 'Windy']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [ \n",
    "                    ('categorical', OneHotEncoder(handle_unknown='ignore'),  \n",
    "                                    selector(dtype_include=[\"object\",\"bool\"]))\n",
    "                    ],\n",
    "                    remainder='passthrough' \n",
    ")\n",
    "\n",
    "preprocessor.fit(X_df)\n",
    "X = preprocessor.transform(X_df)\n",
    "\n",
    "# Notice that now we have 7 columnos\n",
    "print(X.shape)\n",
    "print()\n",
    "\n",
    "# Notice that now the type of the data matrix is numpy, which can already be used by sklearn\n",
    "print(type(X))\n",
    "print()\n",
    "\n",
    "# The first three columns are the dummies for Sky, the second two columns are the dummies for Windy\n",
    "# The last two columns are Temperature and Humidity, untouched\n",
    "# Please, notice that the order of columns has changed (not important, in principle)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDXkuInIduqR"
   },
   "source": [
    "Now, we need to encode the class into integers. We do that with labelencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vfihfozAyP-N",
    "outputId": "31f50b44-194c-40b4-b529-7b40c33d4e74"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_df)\n",
    "\n",
    "y = le.transform(y_df)\n",
    "print(y)\n",
    "\n",
    "# Actually, it seems that sklearn can use the original y_df, so we could have done y = y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7w5y9ASdgVF"
   },
   "source": [
    "Finally, we just copy the code for evaluating decision trees, and for constructing the final model.\n",
    "We apply that to our (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B9sDNvM74QX4",
    "outputId": "17be3067-b07b-4589-d7f3-ad85293773cb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Here, we set our model to classification tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "np.random.seed(42) # reproducibility\n",
    "# We train it\n",
    "clf.fit(X_train, y_train)\n",
    "# We obtain predictions on the test set\n",
    "y_test_pred = clf.predict(X_test)\n",
    "# We compute accuracy\n",
    "accuracy_tree = metrics.accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Accuracy of the tree: {accuracy_tree} \")\n",
    "\n",
    "# We finally compute the final model with all available data\n",
    "\n",
    "final_clf = tree.DecisionTreeClassifier()\n",
    "np.random.seed(42)  # reproducibility\n",
    "final_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "rXrsYLX1assM",
    "outputId": "70425847-3534-4d35-e2dd-d6f2a13cbc01"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "    \n",
    "_ = tree.plot_tree(final_clf, \n",
    "                   feature_names = list(sorted(X_df['Sky'].unique())) + list(sorted(X_df['Windy'].unique())) + ['Temperature', 'Humidity'],\n",
    "                   class_names= list(sorted(y_df.unique())),\n",
    "                   filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_3dHiNA53rdr"
   },
   "outputs": [],
   "source": [
    "# !pip install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yvrx1JqN4yZm"
   },
   "source": [
    "Given that this is a 2-class classification problem, we can construct a confidence interval for the accuracy\n",
    "We can see it is very inaccurate ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JHaewbCxiBQ6",
    "outputId": "08683196-84d3-49d8-9c46-c5757ecd4ebd"
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportion_confint\n",
    "print(f\"Only {len(y_test)} instances on the testing partition\")\n",
    "print(f\"Tree accuracy: {accuracy_tree} \")\n",
    "proportion_confint(len(y_test)* accuracy_tree, len(y_test), method=\"wilson\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADfIN64L4QX4"
   },
   "source": [
    "# Regression trees with holdout evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2r3ejoO4QX4"
   },
   "source": [
    "Let's load the Boston dataset and check its description. Its data about housing prices depending on the characteristics of the zone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jRUioZm04QX4",
    "outputId": "4f06ac16-a8e3-4641-cde4-d9885f1a6a75"
   },
   "outputs": [],
   "source": [
    "# The Boston dataset is also included within sklearn\n",
    "from sklearn.datasets import load_boston\n",
    "boston_meta = load_boston()\n",
    "print(boston_meta.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4R6sLJoI4QX4",
    "outputId": "8e92f814-23aa-48c7-e9ce-5a5d4b4ebbce"
   },
   "outputs": [],
   "source": [
    "X = boston_meta.data\n",
    "y = boston_meta.target\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APMXvjj14QX4"
   },
   "source": [
    "The main change is that we use a DecisionTreeRegressor and the metric is now RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TZ21Wukc4QX5",
    "outputId": "8c020dc6-6c86-4070-d9c0-3204013d8124"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Here, we set our model to classification tree\n",
    "regr = tree.DecisionTreeRegressor()\n",
    "np.random.seed(42) # reproducibility\n",
    "# We train it\n",
    "regr.fit(X_train, y_train)\n",
    "# We obtain predictions on the test set\n",
    "y_test_pred = regr.predict(X_test)\n",
    "# We compute accuracy\n",
    "rmse_tree = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "print(f\"RMSE of the tree: {rmse_tree}\")\n",
    "\n",
    "# We would have to compute the final model with all available data\n",
    "# Not done here, only interested on test RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZnnKRiQyNOH"
   },
   "source": [
    "Is it better than a trivial regressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQiGRsbpyN0z",
    "outputId": "99d4f73e-3b56-4a98-b8de-815d5688fd08"
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "regr_mean = DummyRegressor(strategy=\"mean\")\n",
    "regr_mean.fit(X_train, y_train)\n",
    "rmse_mean = np.sqrt(metrics.mean_squared_error(y_test, regr_mean.predict(X_test)))\n",
    "\n",
    "print(f\"RMSE of the tree: {rmse_tree}\")\n",
    "print(f\"RMSE of dummy(mean): {rmse_mean}\")\n",
    "print(f\"RMSE ratio tree/dummy(mean): {rmse_tree/rmse_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qERBOOPQ0yzI"
   },
   "source": [
    "What about MAE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wJVUu1JO0xiJ",
    "outputId": "dd4f7cb3-3885-4c53-bc19-b495aa7afc5c"
   },
   "outputs": [],
   "source": [
    "mae_tree = metrics.mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "regr_median = DummyRegressor(strategy=\"median\")\n",
    "regr_median.fit(X_train, y_train)\n",
    "mae_median = metrics.mean_absolute_error(y_test, regr_median.predict(X_test))\n",
    "\n",
    "print(f\"MAE of the tree: {mae_tree}\")\n",
    "print(f\"MAE of dummy(median): {mae_median}\")\n",
    "print(f\"MAE ratio tree/dummy(median): {mae_tree/mae_median}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQ0bJSuz4QX5"
   },
   "source": [
    "The tree has more than 10 levels and it is very hard to visualize. Let's visualize one with only four levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "id": "V1-moMyM4QX5",
    "outputId": "61cf7b89-57fa-40e8-918a-c0006cf898e6"
   },
   "outputs": [],
   "source": [
    "regr = tree.DecisionTreeRegressor(max_depth=4)\n",
    "np.random.seed(42) # reproducibility\n",
    "# We train it\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "    \n",
    "_ = tree.plot_tree(regr,\n",
    "                   feature_names = boston_meta.feature_names,\n",
    "                   filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6in65Vuu4QX5"
   },
   "source": [
    "**Now we train model trees (for regression)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBI37quR4QX5"
   },
   "outputs": [],
   "source": [
    "# More info about this implementation of model trees\n",
    "# https://towardsdatascience.com/linear-tree-the-perfect-mix-of-linear-model-and-decision-tree-2eaed21936b7\n",
    "# https://pypi.org/project/linear-tree/\n",
    "\n",
    "# IMPORTANT: This implementation of Model Trees is able to deal with Categorical Features (whose values are encoded as integers 0,1,2, ...)\n",
    "# in order to use categorical features, the parameter categorical_features must be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMTJR8N61dsr"
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade linear-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-rHXrM9B4QX5",
    "outputId": "e4846ad6-5ac9-4720-b7ae-f951363ccb97"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lineartree import LinearTreeRegressor\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "regr = LinearTreeRegressor(base_estimator=LinearRegression())\n",
    "np.random.seed(42) # reproducibility\n",
    "# We train it\n",
    "regr.fit(X_train, y_train)\n",
    "# We obtain predictions on the test set\n",
    "y_test_pred = regr.predict(X_test)\n",
    "# We compute accuracy\n",
    "rmse_tree = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "print(f\"RMSE of the tree: {rmse_tree}\")\n",
    "\n",
    "# We would have to compute the final model with all available data\n",
    "# Not done here, only interested on test RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZMaKH1q86_U"
   },
   "source": [
    "The internal nodes of the model tree below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "xmXWQ1SD4QX5",
    "outputId": "1a64bd02-0480-4638-c958-c116e2faf857"
   },
   "outputs": [],
   "source": [
    "regr.plot_model(feature_names=boston_meta.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeGJtMBM9Djz"
   },
   "source": [
    "In order to check the linear models at the leaves, we have to follow a longer process. What follows shows the coefficient of the linear model at node 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OgM4K5gS4Ac4"
   },
   "outputs": [],
   "source": [
    "leaves = regr.summary(feature_names=boston_meta.feature_names, only_leaves=True, max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ika31dVu4xgB",
    "outputId": "a199ca04-dfdf-4cf9-8b2d-fa2130a66ab4"
   },
   "outputs": [],
   "source": [
    "leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8jpFdkSA6C-H",
    "outputId": "fa389287-3b17-4bb5-a014-a388459dd5b0"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "model_5_coefs = leaves[5]['models'].coef_\n",
    "model_5_intercept = leaves[5]['models'].intercept_\n",
    "pprint(list(zip(boston_meta.feature_names, model_5_coefs)))\n",
    "pprint(f'intercept: {model_5_intercept}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4As4OQmq8FFE"
   },
   "outputs": [],
   "source": [
    "?LinearTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tpo1MG7XEKii"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
