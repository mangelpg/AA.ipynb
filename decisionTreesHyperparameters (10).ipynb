{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45cWJKARCT2Y",
        "outputId": "1dd07234-aa48-4756-80e4-27228e3464c8"
      },
      "outputs": [],
      "source": [
        "# !pip install scikit-learn==0.24.2\n",
        "# !pip install scikit-optimize\n",
        "!pip install git+https://github.com/scikit-optimize/scikit-optimize.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkKc_paMZ-Oh",
        "outputId": "4b5b42ef-e367-4164-f884-298752c136a5"
      },
      "outputs": [],
      "source": [
        "# Checking that everything is correct with skopt (0.9.dev0) and sklearn \n",
        "from skopt import __version__\n",
        "print(__version__)\n",
        "from sklearn import __version__\n",
        "print(__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjO0ZHCkZp30"
      },
      "source": [
        "# DECISION TREE HYPER-PARAMETERS. TUNING DECISION TREES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_5O3DQkZp31"
      },
      "source": [
        "- **max_depth : int or None, optional (default=None)**\n",
        "    The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. Ignored if max_leaf_nodes is not None.\n",
        "    \n",
        "- **min_samples_split : int, optional (default=2)**\n",
        "    The minimum number of samples required to split an internal node.\n",
        "\n",
        "- There are more hyper-parameters: \n",
        "  - https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
        "  - https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tfYm7QAZp32"
      },
      "source": [
        "First, data is loaded, inputs go to X, outputs to y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJD421uMZp33"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_boston\n",
        "from scipy.stats import sem\n",
        "\n",
        "boston = load_boston()\n",
        "X = boston.data\n",
        "y = boston.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQOtMG7hZp35"
      },
      "source": [
        "## COMBINING HYPER-PARAMETER TUNING AND MODEL EVALUATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ry14avEZp36"
      },
      "source": [
        "The combination of model evaluation and hyper-parameter tuning can be understood as an external loop (outer) that trains a model and tests the model, and an internal loop (inner), where the training process consists on looking for the best hyper-parameters, and then obtaining the model with those best hyper-parameters.\n",
        "\n",
        "First, we are going to use **Holdout** (train/test) for model evaluation (external loop or **outer**), and **3-fold crossvalidation** for hyper-parameter tuning (internal loop or **inner**). Hyper-parameters will be adjusted with **Gridsearch**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQQaJrViZp37"
      },
      "source": [
        "#### GRIDSEARCH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rqhsc9OARd3"
      },
      "source": [
        "First of all, let's define our our python function for RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TM7SzJLHAQhZ"
      },
      "outputs": [],
      "source": [
        "def rmse(y_test, y_test_pred):\n",
        "  \"\"\" This is my computation of Root Mean Squared Error \"\"\"\n",
        "  return np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laxLj26PZp37"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Holdout for model evaluation. 33% of available data for test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-SI_kTr82RI"
      },
      "source": [
        "First, let's remember RMSE with default hyper-parameteres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU6g-6PZ87DS",
        "outputId": "0e9870b0-fdfd-492c-c816-127fb098d1ab"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "regr = DecisionTreeRegressor()\n",
        "np.random.seed(42)\n",
        "regr.fit(X=X_train, y=y_train)\n",
        "print(f\"RMSE of tree with default hyper-pars: {rmse(y_test, regr.predict(X=X_test))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRknuZjUZp39",
        "outputId": "23535874-4edb-41bd-cb1e-53acddc7f173"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "# Search space\n",
        "param_grid = {'max_depth': list(range(2,16,2)),\n",
        "              'min_samples_split': list(range(2,16,2))}\n",
        "\n",
        "inner = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# Definition of a 2-step process that self-adjusts 2 hyperpars\n",
        "regr = GridSearchCV(DecisionTreeRegressor(), \n",
        "                   param_grid,\n",
        "                   scoring='neg_mean_squared_error',\n",
        "                   cv=inner, \n",
        "                   n_jobs=1, verbose=1)\n",
        "\n",
        "# Train the self-adjusting process\n",
        "np.random.seed(42)\n",
        "regr.fit(X=X_train, y=y_train)\n",
        "\n",
        "# At this point, regr contains the model with the best hyper-parameters found by gridsearch\n",
        "# and trained on the complete X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZokHzT78udT",
        "outputId": "051cfe0c-c4f0-447e-c99e-c6575b6d6c00"
      },
      "outputs": [],
      "source": [
        "# Now, the performance of regr is computed on the test partition\n",
        "\n",
        "print(f\"RMSE of tree with hyper-parameter tuning (grid-search): {rmse(y_test, regr.predict(X=X_test))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTTNB93mZp4A"
      },
      "source": [
        "Let's see the best hyper-parameters and their score (MSE). We can see that they are near the extremes of parameter space, but not at the extreme."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVeTEIFaZp4B",
        "outputId": "436082b6-51a7-4850-a813-3e2c3bb79c7a"
      },
      "outputs": [],
      "source": [
        "regr.best_params_, -regr.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk6rBqZSZp4I"
      },
      "source": [
        "#### RANDOMIZED SEARCH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7bZU45-Zp4I"
      },
      "source": [
        "Now, let's use **Randomized Search** instead of gridsearch. Only 20 hyper-parameter value combinations will be tried (budget=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urjn49EAZp4J",
        "outputId": "e3a98fca-16f2-4a74-bcdd-811e9696c6cd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
        "from sklearn import metrics\n",
        "\n",
        "# Search space\n",
        "param_grid = {'max_depth': list(range(2,16,2)),\n",
        "              'min_samples_split': list(range(2,16,2))}\n",
        "\n",
        "# Inner evaluation\n",
        "inner = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "budget = 20\n",
        "regr = RandomizedSearchCV(DecisionTreeRegressor(), \n",
        "                         param_grid,\n",
        "                         scoring='neg_mean_squared_error',\n",
        "                         cv=inner, \n",
        "                         n_jobs=1, verbose=1,\n",
        "                         n_iter=budget\n",
        "                        )\n",
        "np.random.seed(42)\n",
        "regr.fit(X=X_train, y=y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2JJyJAn-6Ci",
        "outputId": "2841abf9-8b10-4175-a4b9-563ddb9494e5"
      },
      "outputs": [],
      "source": [
        "# Now, the performance of regr is computed on the test partition\n",
        "\n",
        "print(f\"RMSE of tree with hyper-parameter tuning (random search): {rmse(y_test, regr.predict(X=X_test))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OzNtlMYZp4L",
        "outputId": "54b77c36-650c-4226-edad-5aafc8c9db30"
      },
      "outputs": [],
      "source": [
        "regr.best_params_, -regr.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk1-fYyoZp4N"
      },
      "source": [
        "For **Randomized Search**, we can define the search space with statistical distributions, rather than using particular values as we did before. Below you can see how to use a uniform distribution on integers between 2 and 16 by means of *randint*. For continuous hyper-parameters we could use continuous distributions such as *uniform* or *expon* (exponential)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vyv0cvAZp4O",
        "outputId": "1ca97c50-d1cd-4f2d-b2b0-0baa0264619e"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "from scipy.stats import uniform, expon\n",
        "from scipy.stats import randint as sp_randint\n",
        "\n",
        "# Search space with integer uniform distributions\n",
        "param_grid = {'max_depth': sp_randint(2,16),\n",
        "              'min_samples_split': sp_randint(2,16)}\n",
        "\n",
        "inner = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "budget = 20\n",
        "regr = RandomizedSearchCV(DecisionTreeRegressor(), \n",
        "                         param_grid,\n",
        "                         scoring='neg_mean_squared_error',\n",
        "                         cv=inner, \n",
        "                         n_jobs=1, verbose=1,\n",
        "                         n_iter=budget\n",
        "                        )\n",
        "\n",
        "np.random.seed(42)\n",
        "regr.fit(X=X_train, y=y_train)\n",
        "\n",
        "# At this point, regr contains the model with the best hyper-parameters found by gridsearch\n",
        "# and trained on the complete X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRppQBOiA9fI",
        "outputId": "8808dac2-d21e-46f5-d543-0b982843a1e3"
      },
      "outputs": [],
      "source": [
        "# Now, the performance of regr is computed on the test partition\n",
        "\n",
        "print(f\"RMSE of tree with hyper-parameter tuning (random search II): {rmse(y_test, regr.predict(X=X_test))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhMPDyL8Zp4Q",
        "outputId": "5466939d-35e0-4a70-a0c4-c3cf5807e50d"
      },
      "outputs": [],
      "source": [
        "regr.best_params_, -regr.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "je3hVWP9Zp4S"
      },
      "source": [
        "What if we wanted to do **model evaluation with 5-fold crossvalidation** and **hyper-parameter tuning with 3-fold crossvalidation**? This is called nested crossvalidation (https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html). There is an external loop (for evaluating models) and an internal loop (for hyper-parameter tuning)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkJD1ifoZp4S",
        "outputId": "adf4d58a-7582-49a9-fc43-e6e3d09d6445"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
        "from sklearn import metrics\n",
        "\n",
        "# random_state=0 for reproducibility\n",
        "# Evaluation of model (outer loop)\n",
        "outer = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "from scipy.stats import uniform, expon\n",
        "\n",
        "# Search space\n",
        "param_grid = {'max_depth': list(range(2,16,2)),\n",
        "              'min_samples_split': list(range(2,16,2))}\n",
        "\n",
        "inner = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "budget = 20\n",
        "# This is the internal 3-fold crossvalidation for hyper-parameter tuning\n",
        "regr = RandomizedSearchCV(DecisionTreeRegressor(), \n",
        "                         param_grid,\n",
        "                         scoring='neg_mean_squared_error',\n",
        "                         # 3-fold for hyper-parameter tuning\n",
        "                         cv=inner, \n",
        "                         n_jobs=1, verbose=1,\n",
        "                         n_iter=budget\n",
        "                        )\n",
        "\n",
        "# This is the external 5-fold crossvalidation for model evaluation\n",
        "# Notice that regr is the model resulting of hyper-parameter tuning\n",
        "np.random.seed(42)\n",
        "\n",
        "# For sklearn, higher scores are better. Given that MSE is an error (smaller is better), the corresponding score is -MSE\n",
        "scores = -cross_val_score(regr, \n",
        "                            X, y, \n",
        "                            scoring='neg_mean_squared_error', \n",
        "                            cv = outer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxeEDgv1Zp4U",
        "outputId": "803b9784-1e14-488b-bd56-f668e6adb6e3"
      },
      "outputs": [],
      "source": [
        "print(scores)\n",
        "# The score was MSE, we want RMSE\n",
        "scores = np.sqrt(scores)\n",
        "# The mean of the 5-fold crossvalidation is the final score of the model\n",
        "print(f\"{scores.mean()} +- {scores.std()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdfqhEw9Zp4W"
      },
      "source": [
        "#### OBTAINING THE FINAL MODEL (FOR DEPLOYMENT, OR FOR SENDING TO A COMPETITION, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5w47vRHZp4X"
      },
      "source": [
        "If at the end, we need a final model, we can get it by fitting regr to all the available data. Let us remember that regr does hyper.parameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Kvg0RX-Zp4X",
        "outputId": "a0a7ccc8-8ed4-44b8-aec5-e2a5f3d857e5"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "# Fitting again the randomized search HPO\n",
        "regrFinal = regr.fit(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRfsLFLTZp4Z",
        "outputId": "0883f44a-c341-4c20-ebd2-d5dee439df93"
      },
      "outputs": [],
      "source": [
        "regr.best_params_, -regr.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XeQqmjrZp4e"
      },
      "source": [
        "#### MODEL BASED OPTIMIZATION (BAYESIAN OPTIMIZATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNwHbEIsZp4f"
      },
      "source": [
        "scikit-optimize (skopt) will be used for this: https://scikit-optimize.github.io. **Holdout** for model evaluation and **3-fold crossvalidation** for hyper-parameter tuning (with **Model Based Optimization** )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmxEk_w4cEb7",
        "outputId": "7ea71da5-cc90-423a-e95d-1036702753c6"
      },
      "outputs": [],
      "source": [
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Integer, Real, Categorical\n",
        "from sklearn import metrics\n",
        "from skopt.plots import plot_objective, plot_histogram, plot_convergence\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Search space with integer uniform distributions\n",
        "param_grid = {'max_depth': Integer(2,16),\n",
        "              'min_samples_split': Integer(2,16)}\n",
        "\n",
        "inner = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "budget = 20\n",
        "regr = BayesSearchCV(DecisionTreeRegressor(), \n",
        "                    param_grid,\n",
        "                    scoring='neg_mean_squared_error',\n",
        "                    cv=inner,    \n",
        "                    n_jobs=1, verbose=1,\n",
        "                    n_iter=budget\n",
        "                    )\n",
        "np.random.seed(42)\n",
        "regr.fit(X=X_train, y=y_train)\n",
        "\n",
        "# At this point, regr contains the model with the best hyper-parameters found by bayessearch\n",
        "# and trained on the complete X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIqeUTQ6Zp4k",
        "outputId": "6cdd71b3-a1f2-400d-bfe7-e8998db90e0e"
      },
      "outputs": [],
      "source": [
        "# Now, the performance of regr is computed on the test partition\n",
        "\n",
        "print(f\"RMSE of tree with hyper-parameter tuning (bayesian optimization): {rmse(y_test, regr.predict(X=X_test))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlZ321QBZp4l",
        "outputId": "348eb11c-9f3e-469a-bdd4-8a42f28b18f6"
      },
      "outputs": [],
      "source": [
        "regr.best_params_, -regr.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YSNFqSaF6Qx"
      },
      "source": [
        "We can check if the optimization has converged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "FjW8T92qFu7f",
        "outputId": "283a5368-7284-4eb9-cd71-17a5083c56fd"
      },
      "outputs": [],
      "source": [
        "_ = plot_convergence(regr.optimizer_results_[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "6yEHkN0ECMJ-",
        "outputId": "7c11b8b7-482d-4519-9587-b40e4296b57d"
      },
      "outputs": [],
      "source": [
        "_ = plot_objective(regr.optimizer_results_[0],\n",
        "                   dimensions=['max_depth', 'min_samples_split'],\n",
        "                   n_minimum_search=int(1e8))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gl_FlpQUdbdZ"
      },
      "outputs": [],
      "source": [
        "#### MODEL BASED OPTIMIZATION (BAYESIAN OPTIMIZATION) WITH LISTS OF SPACES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiyxunjnCMKA",
        "outputId": "33ae06a2-a5e6-41c9-dbd5-86704d8dd06e"
      },
      "outputs": [],
      "source": [
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Integer, Real, Categorical\n",
        "from sklearn import metrics\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('model', DecisionTreeRegressor())\n",
        "])\n",
        "\n",
        "\n",
        "# Search space for DT\n",
        "param_grid1 = {\n",
        "    'model': [DecisionTreeRegressor()],\n",
        "    'model__max_depth': Integer(2,16),\n",
        "    'model__min_samples_split': Integer(2,16)}\n",
        "\n",
        "# Search space for KNN\n",
        "param_grid2 = {\n",
        "    'model': [KNeighborsRegressor()],\n",
        "    'model__n_neighbors': Integer(2,10)\n",
        "    \n",
        "}\n",
        "\n",
        "# List of the two spaces\n",
        "param_grid = [param_grid1, param_grid2]\n",
        "\n",
        "inner = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "budget = 20\n",
        "refr = BayesSearchCV(pipe, \n",
        "                    param_grid,\n",
        "                    scoring='neg_mean_squared_error',\n",
        "                    cv=inner,    \n",
        "                    n_jobs=1, verbose=1,\n",
        "                    n_iter=budget\n",
        "                    )\n",
        "\n",
        "np.random.seed(42)\n",
        "regr.fit(X=X_train, y=y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzW6Fa5WCMKB",
        "outputId": "31e14d8d-d2be-4359-a05e-e0ff7f31ef5b"
      },
      "outputs": [],
      "source": [
        "# At this point, regr contains the model with the best hyper-parameters found by bayessearch\n",
        "# and trained on the complete X_train\n",
        "\n",
        "# Now, the performance of regr is computed on the test partition\n",
        "\n",
        "y_test_pred = regr.predict(X_test)\n",
        "print(metrics.mean_squared_error(y_test, y_test_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWcVZWVPCMKC",
        "outputId": "69f9a1cf-8272-43d5-969c-d246128ed387"
      },
      "outputs": [],
      "source": [
        "regr.best_params_, -regr.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCtcKNzlCMKC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "decisionTreesHyperparameters.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
